#!/usr/bin/env python3
"""
LLM í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ëª¨ë“  LLM API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ê³  ì—°ê²°ë˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import os
import sys

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸° (ë¡œì»¬ì—ì„œ ì„¤ì • í•„ìš”)
# export ANTHROPIC_API_KEY="your_key_here"
# export OPENAI_API_KEY="your_key_here" 
# export GOOGLE_AI_API_KEY="your_key_here"
# export PERPLEXITY_API_KEY="your_key_here"

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.llm_clients.base import LLMRequest
from src.llm_clients.claude import ClaudeClient
from src.llm_clients.gpt import GPTClient
from src.llm_clients.gemini import GeminiClient
from src.llm_clients.perplexity import PerplexityClient
from src.llm_clients.client_factory import get_llm_factory
# LLM ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤ì€ ê°œë³„ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì²˜ë¦¬


def print_status(message: str, status: str = "INFO"):
    """ìƒíƒœ ë©”ì‹œì§€ ì¶œë ¥"""
    colors = {
        "INFO": "\033[94m",      # íŒŒë€ìƒ‰
        "SUCCESS": "\033[92m",   # ì´ˆë¡ìƒ‰
        "ERROR": "\033[91m",     # ë¹¨ê°„ìƒ‰
        "WARNING": "\033[93m"    # ë…¸ë€ìƒ‰
    }
    reset = "\033[0m"
    print(f"{colors.get(status, '')}{status}: {message}{reset}")


def test_claude_client():
    """Claude í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    print_status("ğŸ¤– Claude í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            print_status("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "ERROR")
            return False
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = ClaudeClient(model_name="sonnet-3.5", api_key=api_key)
        
        # í…ŒìŠ¤íŠ¸ ìš”ì²­
        request = LLMRequest(
            prompt="ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. 'ì—°ê²° ì„±ê³µ'ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.",
            agent_type="test",
            max_tokens=50
        )
        
        response = client.generate_response(request)
        
        print_status(f"Claude ì‘ë‹µ: {response.content[:100]}...", "SUCCESS")
        print_status(f"í† í° ì‚¬ìš©: {response.tokens_used}, ë¹„ìš©: ${response.cost:.4f}", "INFO")
        return True
        
    except Exception as e:
        print_status(f"Claude í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def test_gpt_client():
    """GPT í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    print_status("ğŸ§  GPT í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            print_status("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "ERROR")
            return False
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = GPTClient(model_name="gpt-4o", api_key=api_key)
        
        # í…ŒìŠ¤íŠ¸ ìš”ì²­
        request = LLMRequest(
            prompt="Hello! This is a connection test. Please respond with 'Connection successful'.",
            agent_type="test",
            max_tokens=50
        )
        
        response = client.generate_response(request)
        
        print_status(f"GPT ì‘ë‹µ: {response.content[:100]}...", "SUCCESS")
        print_status(f"í† í° ì‚¬ìš©: {response.tokens_used}, ë¹„ìš©: ${response.cost:.4f}", "INFO")
        return True
        
    except Exception as e:
        print_status(f"GPT í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def test_gemini_client():
    """Gemini í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    print_status("ğŸ’ Gemini í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        api_key = os.getenv('GOOGLE_AI_API_KEY')
        if not api_key:
            print_status("GOOGLE_AI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "ERROR")
            return False
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = GeminiClient(model_name="flash-1.5", api_key=api_key)
        
        # í…ŒìŠ¤íŠ¸ ìš”ì²­
        request = LLMRequest(
            prompt="ì•ˆë…•í•˜ì„¸ìš”! ì—°ê²° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. 'ì—°ê²° ì„±ê³µ'ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.",
            agent_type="test",
            max_tokens=50
        )
        
        response = client.generate_response(request)
        
        print_status(f"Gemini ì‘ë‹µ: {response.content[:100]}...", "SUCCESS")
        print_status(f"í† í° ì‚¬ìš©: {response.tokens_used}, ë¹„ìš©: ${response.cost:.6f}", "INFO")
        return True
        
    except Exception as e:
        print_status(f"Gemini í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def test_perplexity_client():
    """Perplexity í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    print_status("ğŸ” Perplexity í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        api_key = os.getenv('PERPLEXITY_API_KEY')
        if not api_key:
            print_status("PERPLEXITY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "ERROR")
            return False
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = PerplexityClient(model_name="sonar-pro", api_key=api_key)
        
        # í…ŒìŠ¤íŠ¸ ìš”ì²­
        request = LLMRequest(
            prompt="Hello! This is a connection test. Please respond with 'Connection successful'.",
            agent_type="test",
            max_tokens=50
        )
        
        response = client.generate_response(request)
        
        print_status(f"Perplexity ì‘ë‹µ: {response.content[:100]}...", "SUCCESS")
        print_status(f"í† í° ì‚¬ìš©: {response.tokens_used}, ë¹„ìš©: ${response.cost:.6f}", "INFO")
        return True
        
    except Exception as e:
        print_status(f"Perplexity í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def test_llm_factory():
    """LLM íŒ©í† ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸"""
    print_status("ğŸ­ LLM íŒ©í† ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # íŒ©í† ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        factory = get_llm_factory()
        
        # ê° ì—ì´ì „íŠ¸ íƒ€ì…ë³„ í´ë¼ì´ì–¸íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        test_agents = [
            "cio",
            "technical_analyst", 
            "sector_researcher",
            "valuation_analyst"
        ]
        
        success_count = 0
        
        for agent_type in test_agents:
            try:
                client = factory.create_client(agent_type)
                print_status(f"âœ“ {agent_type}: {client}", "SUCCESS")
                success_count += 1
            except Exception as e:
                print_status(f"âœ— {agent_type}: {e}", "ERROR")
        
        print_status(f"íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(test_agents)} ì„±ê³µ", "INFO")
        return success_count == len(test_agents)
        
    except Exception as e:
        print_status(f"íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def test_error_handling():
    """ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸"""
    print_status("âš ï¸ ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ì˜ëª»ëœ API í‚¤ë¡œ í…ŒìŠ¤íŠ¸
        client = ClaudeClient(model_name="sonnet-3.5", api_key="invalid-key")
        
        request = LLMRequest(
            prompt="í…ŒìŠ¤íŠ¸",
            agent_type="test",
            max_tokens=10
        )
        
        try:
            response = client.generate_response(request)
            print_status("ì—ëŸ¬ê°€ ë°œìƒí•´ì•¼ í•˜ëŠ”ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤ - í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨", "ERROR")
            return False
        except Exception as e:
            # ì–´ë–¤ ì¢…ë¥˜ì˜ ì—ëŸ¬ë“  ë°œìƒí•˜ë©´ ì„±ê³µ
            print_status(f"ì˜ˆìƒëœ ì—ëŸ¬ ë°œìƒ: {e}", "SUCCESS")
            return True
            
    except Exception as e:
        print_status(f"ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print_status("ğŸš€ LLM í´ë¼ì´ì–¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘", "INFO")
    print("=" * 60)
    
    test_results = {}
    
    # ê°œë³„ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
    test_results["claude"] = test_claude_client()
    print("-" * 60)
    
    test_results["gpt"] = test_gpt_client()
    print("-" * 60)
    
    test_results["gemini"] = test_gemini_client()
    print("-" * 60)
    
    test_results["perplexity"] = test_perplexity_client()
    print("-" * 60)
    
    # í†µí•© í…ŒìŠ¤íŠ¸
    test_results["factory"] = test_llm_factory()
    print("-" * 60)
    
    test_results["error_handling"] = test_error_handling()
    print("-" * 60)
    
    # ê²°ê³¼ ìš”ì•½
    print_status("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½", "INFO")
    print("=" * 60)
    
    success_count = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ…" if result else "âŒ"
        color = "SUCCESS" if result else "ERROR"
        print_status(f"{status} {test_name}: {'í†µê³¼' if result else 'ì‹¤íŒ¨'}", color)
        if result:
            success_count += 1
    
    print("-" * 60)
    
    if success_count == total_tests:
        print_status(f"ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ({success_count}/{total_tests})", "SUCCESS")
        print_status("Phase 1.1 í•˜ì´ë¸Œë¦¬ë“œ LLM ì¸í”„ë¼ êµ¬ì¶• ì™„ë£Œ!", "SUCCESS")
    else:
        print_status(f"âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({success_count}/{total_tests})", "WARNING")
        print_status("ì‹¤íŒ¨í•œ API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "WARNING")
    
    return success_count == total_tests


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)