#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìºì‹œ ê´€ë¦¬ìž ëª¨ë“ˆ

Streamlit ëŒ€ì‹œë³´ë“œì˜ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ê³ ê¸‰ ìºì‹± ì‹œìŠ¤í…œ
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Union
import hashlib
import pickle
import json
import time
from functools import wraps
import threading
import logging

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class CacheMetrics:
    """ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì """
    
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.evictions = 0
        self.total_size = 0
        self.start_time = datetime.now()
        self.access_times = []
        self._lock = threading.Lock()
    
    def record_hit(self, access_time: float = None):
        """ìºì‹œ ížˆíŠ¸ ê¸°ë¡"""
        with self._lock:
            self.hits += 1
            if access_time:
                self.access_times.append(access_time)
    
    def record_miss(self):
        """ìºì‹œ ë¯¸ìŠ¤ ê¸°ë¡"""
        with self._lock:
            self.misses += 1
    
    def record_eviction(self):
        """ìºì‹œ ì œê±° ê¸°ë¡"""
        with self._lock:
            self.evictions += 1
    
    def get_hit_rate(self) -> float:
        """ìºì‹œ ížˆíŠ¸ìœ¨ ê³„ì‚°"""
        total = self.hits + self.misses
        return (self.hits / total) * 100 if total > 0 else 0
    
    def get_avg_access_time(self) -> float:
        """í‰ê·  ì ‘ê·¼ ì‹œê°„"""
        return np.mean(self.access_times) if self.access_times else 0
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        return {
            'hits': self.hits,
            'misses': self.misses,
            'evictions': self.evictions,
            'hit_rate': self.get_hit_rate(),
            'total_requests': self.hits + self.misses,
            'avg_access_time_ms': self.get_avg_access_time() * 1000,
            'uptime_hours': (datetime.now() - self.start_time).total_seconds() / 3600
        }

class AdvancedCacheManager:
    """ê³ ê¸‰ ìºì‹œ ê´€ë¦¬ìž"""
    
    def __init__(self, max_size: int = 100, default_ttl: int = 300):
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.cache_data = {}
        self.access_times = {}
        self.creation_times = {}
        self.access_counts = {}
        self.metrics = CacheMetrics()
        self._lock = threading.Lock()
        
        # Streamlit ì„¸ì…˜ ìƒíƒœì— ìºì‹œ ì €ìž¥
        if 'advanced_cache' not in st.session_state:
            st.session_state.advanced_cache = {}
            st.session_state.cache_metadata = {}
    
    def _generate_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{func_name}:{str(args)}:{str(sorted(kwargs.items()))}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _is_expired(self, key: str) -> bool:
        """ìºì‹œ ë§Œë£Œ í™•ì¸"""
        if key not in self.creation_times:
            return True
        
        metadata = st.session_state.cache_metadata.get(key, {})
        ttl = metadata.get('ttl', self.default_ttl)
        creation_time = self.creation_times[key]
        
        return (time.time() - creation_time) > ttl
    
    def _evict_lru(self):
        """LRU ê¸°ë°˜ ìºì‹œ ì œê±°"""
        if len(st.session_state.advanced_cache) >= self.max_size:
            # ê°€ìž¥ ì˜¤ëž˜ëœ ì ‘ê·¼ ì‹œê°„ì„ ê°€ì§„ í•­ëª© ì œê±°
            oldest_key = min(
                self.access_times.keys(),
                key=lambda k: self.access_times[k]
            )
            self._remove_item(oldest_key)
            self.metrics.record_eviction()
    
    def _remove_item(self, key: str):
        """ìºì‹œ í•­ëª© ì œê±°"""
        with self._lock:
            st.session_state.advanced_cache.pop(key, None)
            st.session_state.cache_metadata.pop(key, None)
            self.access_times.pop(key, None)
            self.creation_times.pop(key, None)
            self.access_counts.pop(key, None)
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        start_time = time.time()
        
        with self._lock:
            if key in st.session_state.advanced_cache and not self._is_expired(key):
                # ìºì‹œ ížˆíŠ¸
                self.access_times[key] = time.time()
                self.access_counts[key] = self.access_counts.get(key, 0) + 1
                
                access_time = time.time() - start_time
                self.metrics.record_hit(access_time)
                
                return st.session_state.advanced_cache[key]
            else:
                # ìºì‹œ ë¯¸ìŠ¤ ë˜ëŠ” ë§Œë£Œ
                if key in st.session_state.advanced_cache:
                    self._remove_item(key)  # ë§Œë£Œëœ í•­ëª© ì œê±°
                
                self.metrics.record_miss()
                return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """ìºì‹œì— ë°ì´í„° ì €ìž¥"""
        with self._lock:
            # ìš©ëŸ‰ ì´ˆê³¼ ì‹œ LRU ì œê±°
            self._evict_lru()
            
            # ìƒˆ í•­ëª© ì¶”ê°€
            st.session_state.advanced_cache[key] = value
            st.session_state.cache_metadata[key] = {
                'ttl': ttl or self.default_ttl,
                'size': len(str(value)),  # ëŒ€ëžµì ì¸ í¬ê¸°
                'created': datetime.now().isoformat()
            }
            
            current_time = time.time()
            self.access_times[key] = current_time
            self.creation_times[key] = current_time
            self.access_counts[key] = 0
    
    def clear(self):
        """ì „ì²´ ìºì‹œ ì´ˆê¸°í™”"""
        with self._lock:
            st.session_state.advanced_cache.clear()
            st.session_state.cache_metadata.clear()
            self.access_times.clear()
            self.creation_times.clear()
            self.access_counts.clear()
    
    def get_cache_info(self) -> Dict[str, Any]:
        """ìºì‹œ ì •ë³´ ë°˜í™˜"""
        total_size = sum(
            metadata.get('size', 0) 
            for metadata in st.session_state.cache_metadata.values()
        )
        
        return {
            'cache_size': len(st.session_state.advanced_cache),
            'max_size': self.max_size,
            'total_size_bytes': total_size,
            'metrics': self.metrics.get_stats(),
            'items': [
                {
                    'key': key[:16] + '...' if len(key) > 16 else key,
                    'size': st.session_state.cache_metadata.get(key, {}).get('size', 0),
                    'access_count': self.access_counts.get(key, 0),
                    'created': st.session_state.cache_metadata.get(key, {}).get('created', 'Unknown'),
                    'ttl': st.session_state.cache_metadata.get(key, {}).get('ttl', 0)
                }
                for key in st.session_state.advanced_cache.keys()
            ]
        }

# ê¸€ë¡œë²Œ ìºì‹œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
cache_manager = AdvancedCacheManager()

def smart_cache(ttl: int = 300, max_size: int = 100, key_func: Optional[Callable] = None):
    """ìŠ¤ë§ˆíŠ¸ ìºì‹œ ë°ì½”ë ˆì´í„°"""
    
    def decorator(func: Callable):
        func._cache_stats = {'calls': 0, 'cache_hits': 0}
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ì»¤ìŠ¤í…€ í‚¤ í•¨ìˆ˜ê°€ ìžˆìœ¼ë©´ ì‚¬ìš©
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = cache_manager._generate_key(func.__name__, args, kwargs)
            
            func._cache_stats['calls'] += 1
            
            # ìºì‹œì—ì„œ í™•ì¸
            cached_result = cache_manager.get(cache_key)
            if cached_result is not None:
                func._cache_stats['cache_hits'] += 1
                return cached_result
            
            # í•¨ìˆ˜ ì‹¤í–‰
            start_time = time.time()
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            # ê²°ê³¼ ìºì‹œì— ì €ìž¥
            cache_manager.set(cache_key, result, ttl)
            
            # ì‹¤í–‰ ì‹œê°„ì´ ê¸¸ë©´ ë¡œê·¸
            if execution_time > 1.0:
                logger.info(f"Function {func.__name__} took {execution_time:.2f}s")
            
            return result
        
        wrapper.cache_info = lambda: func._cache_stats
        wrapper.cache_clear = lambda: cache_manager.clear()
        
        return wrapper
    return decorator

class DataFrameCache:
    """DataFrame ì „ìš© ìµœì í™” ìºì‹œ"""
    
    def __init__(self):
        self.cache = {}
        self.metadata = {}
    
    def cache_dataframe(self, df: pd.DataFrame, key: str, ttl: int = 600) -> str:
        """DataFrameì„ íš¨ìœ¨ì ìœ¼ë¡œ ìºì‹œ"""
        # DataFrameì„ Parquet í˜•íƒœë¡œ ì§ë ¬í™” (ë” íš¨ìœ¨ì )
        try:
            # ë©”ëª¨ë¦¬ ë‚´ parquet ì €ìž¥
            buffer = df.to_parquet()
            
            self.cache[key] = buffer
            self.metadata[key] = {
                'timestamp': time.time(),
                'ttl': ttl,
                'shape': df.shape,
                'memory_usage': df.memory_usage(deep=True).sum(),
                'dtypes': df.dtypes.to_dict()
            }
            
            return key
        except Exception as e:
            logger.error(f"DataFrame caching failed: {e}")
            return None
    
    def get_dataframe(self, key: str) -> Optional[pd.DataFrame]:
        """ìºì‹œì—ì„œ DataFrame ê°€ì ¸ì˜¤ê¸°"""
        if key not in self.cache:
            return None
        
        metadata = self.metadata[key]
        if time.time() - metadata['timestamp'] > metadata['ttl']:
            # ë§Œë£Œëœ ìºì‹œ ì œê±°
            del self.cache[key]
            del self.metadata[key]
            return None
        
        try:
            # Parquet ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³µì›
            return pd.read_parquet(self.cache[key])
        except Exception as e:
            logger.error(f"DataFrame cache retrieval failed: {e}")
            return None
    
    def get_info(self) -> Dict[str, Any]:
        """DataFrame ìºì‹œ ì •ë³´"""
        total_memory = sum(meta['memory_usage'] for meta in self.metadata.values())
        
        return {
            'cached_dataframes': len(self.cache),
            'total_memory_mb': total_memory / (1024 * 1024),
            'items': [
                {
                    'key': key,
                    'shape': meta['shape'],
                    'memory_mb': meta['memory_usage'] / (1024 * 1024),
                    'age_minutes': (time.time() - meta['timestamp']) / 60
                }
                for key, meta in self.metadata.items()
            ]
        }

# DataFrame ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
df_cache = DataFrameCache()

class QueryCache:
    """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìºì‹œ"""
    
    def __init__(self):
        self.cache = {}
        self.query_stats = {}
    
    def cache_query_result(self, query_hash: str, result: Any, execution_time: float):
        """ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œ"""
        self.cache[query_hash] = {
            'result': result,
            'timestamp': time.time(),
            'execution_time': execution_time
        }
        
        # ì¿¼ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸
        if query_hash not in self.query_stats:
            self.query_stats[query_hash] = {
                'executions': 0,
                'total_time': 0,
                'cache_hits': 0
            }
        
        self.query_stats[query_hash]['executions'] += 1
        self.query_stats[query_hash]['total_time'] += execution_time
    
    def get_cached_result(self, query_hash: str, ttl: int = 300) -> Optional[Any]:
        """ìºì‹œëœ ì¿¼ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        if query_hash not in self.cache:
            return None
        
        cached_item = self.cache[query_hash]
        if time.time() - cached_item['timestamp'] > ttl:
            del self.cache[query_hash]
            return None
        
        # ìºì‹œ ížˆíŠ¸ ê¸°ë¡
        if query_hash in self.query_stats:
            self.query_stats[query_hash]['cache_hits'] += 1
        
        return cached_item['result']
    
    def get_query_performance(self) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ ì„±ëŠ¥ í†µê³„"""
        performance = []
        
        for query_hash, stats in self.query_stats.items():
            avg_time = stats['total_time'] / stats['executions'] if stats['executions'] > 0 else 0
            cache_hit_rate = (stats['cache_hits'] / stats['executions']) * 100 if stats['executions'] > 0 else 0
            
            performance.append({
                'query_hash': query_hash[:16] + '...',
                'executions': stats['executions'],
                'avg_execution_time_ms': avg_time * 1000,
                'cache_hit_rate': cache_hit_rate,
                'total_time_saved_ms': stats['cache_hits'] * avg_time * 1000
            })
        
        return sorted(performance, key=lambda x: x['total_time_saved_ms'], reverse=True)

# ì¿¼ë¦¬ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
query_cache = QueryCache()

def cache_database_query(ttl: int = 300):
    """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìºì‹œ ë°ì½”ë ˆì´í„°"""
    
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ì¿¼ë¦¬ í•´ì‹œ ìƒì„±
            query_hash = hashlib.md5(
                f"{func.__name__}:{str(args)}:{str(sorted(kwargs.items()))}".encode()
            ).hexdigest()
            
            # ìºì‹œì—ì„œ í™•ì¸
            cached_result = query_cache.get_cached_result(query_hash, ttl)
            if cached_result is not None:
                return cached_result
            
            # ì¿¼ë¦¬ ì‹¤í–‰
            start_time = time.time()
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            # ê²°ê³¼ ìºì‹œ
            query_cache.cache_query_result(query_hash, result, execution_time)
            
            return result
        
        return wrapper
    return decorator

def optimize_streamlit_performance():
    """Streamlit ì„±ëŠ¥ ìµœì í™” ì„¤ì •"""
    
    # ìºì‹œ ì„¤ì • ìµœì í™”
    st.set_page_config(
        page_title="Performance Optimized Dashboard",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì •
    if 'performance_mode' not in st.session_state:
        st.session_state.performance_mode = True
    
    # ìžë™ ìƒˆë¡œê³ ì¹¨ ì œí•œ
    if 'last_refresh' not in st.session_state:
        st.session_state.last_refresh = time.time()

def display_cache_analytics():
    """ìºì‹œ ë¶„ì„ ì •ë³´ í‘œì‹œ"""
    
    st.subheader("ðŸ“Š ìºì‹œ ì„±ëŠ¥ ë¶„ì„")
    
    # ìºì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    cache_info = cache_manager.get_cache_info()
    df_info = df_cache.get_info()
    query_performance = query_cache.get_query_performance()
    
    # ë©”íŠ¸ë¦­ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ìºì‹œ ížˆíŠ¸ìœ¨",
            f"{cache_info['metrics']['hit_rate']:.1f}%",
            help="ìºì‹œì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì€ ë¹„ìœ¨"
        )
    
    with col2:
        st.metric(
            "ìºì‹œëœ í•­ëª©",
            f"{cache_info['cache_size']}/{cache_info['max_size']}",
            help="í˜„ìž¬ ìºì‹œëœ í•­ëª© ìˆ˜"
        )
    
    with col3:
        st.metric(
            "í‰ê·  ì‘ë‹µì‹œê°„",
            f"{cache_info['metrics']['avg_access_time_ms']:.1f}ms",
            help="ìºì‹œ ì ‘ê·¼ í‰ê·  ì‹œê°„"
        )
    
    with col4:
        st.metric(
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
            f"{df_info['total_memory_mb']:.1f}MB",
            help="DataFrame ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"
        )
    
    # ìƒì„¸ ë¶„ì„
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ðŸ“ˆ ìºì‹œ ížˆíŠ¸ìœ¨ ì¶”ì´")
        
        # ë”ë¯¸ ížˆíŠ¸ìœ¨ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ì‹œê³„ì—´ ë°ì´í„° í•„ìš”)
        hit_rates = [95.2, 96.1, 94.8, 97.3, 95.9, 96.7, 98.1]
        times = ['6ì‹œê°„ì „', '5ì‹œê°„ì „', '4ì‹œê°„ì „', '3ì‹œê°„ì „', '2ì‹œê°„ì „', '1ì‹œê°„ì „', 'í˜„ìž¬']
        
        chart_data = pd.DataFrame({
            'time': times,
            'hit_rate': hit_rates
        })
        
        st.line_chart(chart_data.set_index('time'))
    
    with col2:
        st.markdown("#### ðŸ” ì¿¼ë¦¬ ì„±ëŠ¥")
        
        if query_performance:
            perf_df = pd.DataFrame(query_performance)
            st.dataframe(perf_df, use_container_width=True)
        else:
            st.info("ì¿¼ë¦¬ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìºì‹œ ê´€ë¦¬ ë„êµ¬
    st.markdown("#### ðŸ› ï¸ ìºì‹œ ê´€ë¦¬")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ðŸ§¹ ìºì‹œ ì •ë¦¬"):
            cache_manager.clear()
            st.success("âœ… ëª¨ë“  ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    with col2:
        if st.button("ðŸ“Š ìºì‹œ ìµœì í™”"):
            st.success("âœ… ìºì‹œê°€ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    with col3:
        if st.button("ðŸ“ˆ ì„±ëŠ¥ ë¶„ì„"):
            st.info("ðŸ“ˆ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°
def monitor_performance(func_name: str = None):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = 0  # ì‹¤ì œë¡œëŠ” psutil ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì¸¡ì •
            
            try:
                result = func(*args, **kwargs)
                success = True
                error = None
            except Exception as e:
                result = None
                success = False
                error = str(e)
                raise
            finally:
                execution_time = time.time() - start_time
                
                # ì„±ëŠ¥ ë¡œê·¸ ê¸°ë¡
                perf_data = {
                    'function': func_name or func.__name__,
                    'execution_time': execution_time,
                    'success': success,
                    'error': error,
                    'timestamp': datetime.now().isoformat()
                }
                
                # ì„¸ì…˜ ìƒíƒœì— ì„±ëŠ¥ ë°ì´í„° ì €ìž¥
                if 'performance_logs' not in st.session_state:
                    st.session_state.performance_logs = []
                
                st.session_state.performance_logs.append(perf_data)
                
                # ìµœê·¼ 100ê°œ ë¡œê·¸ë§Œ ìœ ì§€
                if len(st.session_state.performance_logs) > 100:
                    st.session_state.performance_logs = st.session_state.performance_logs[-100:]
            
            return result
        
        return wrapper
    return decorator