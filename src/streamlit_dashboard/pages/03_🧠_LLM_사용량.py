#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM ì‚¬ìš©ëŸ‰ í˜ì´ì§€

LangGraph ììœ¨ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ LLM API ì‚¬ìš©ëŸ‰, ë¹„ìš© ë° ì„±ëŠ¥ ë¶„ì„
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import numpy as np
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from src.streamlit_dashboard.utils.dashboard_utils import (
    cached_function, format_currency, format_percentage,
    get_time_range_filter, create_summary_cards, add_custom_css,
    format_large_number
)
from src.streamlit_dashboard.utils.chart_helpers import (
    create_line_chart, create_bar_chart, create_pie_chart,
    COLOR_PALETTE, TRADING_COLORS
)
from src.streamlit_dashboard.components.metrics_cards import (
    CountMetricCard, FinancialMetricCard, PercentageMetricCard,
    create_compact_metric_row
)

try:
    from src.database.schema import db_manager
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LLM ì‚¬ìš©ëŸ‰",
    page_icon="ğŸ§ ",
    layout="wide"
)

add_custom_css()

# í˜ì´ì§€ ì œëª©
st.title("ğŸ§  LLM ì‚¬ìš©ëŸ‰ ë¶„ì„")
st.markdown("**Large Language Model API ì‚¬ìš©ëŸ‰, ë¹„ìš© ë° ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤**")

# í•„í„° ë° ì œì–´
col1, col2, col3, col4 = st.columns(4)

with col1:
    time_range = st.selectbox(
        "ğŸ“… ë¶„ì„ ê¸°ê°„",
        ["1ì¼", "1ì£¼", "1ê°œì›”", "3ê°œì›”", "ì „ì²´"],
        index=2,
        key="llm_time_range"
    )

with col2:
    model_filter = st.multiselect(
        "ğŸ¤– ëª¨ë¸ ì„ íƒ",
        ["GPT-4", "GPT-3.5-Turbo", "Claude-3", "Gemini-Pro", "Perplexity"],
        default=["GPT-4", "Claude-3"],
        key="llm_model_filter"
    )

with col3:
    metric_view = st.selectbox(
        "ğŸ“Š í‘œì‹œ ë°©ì‹",
        ["í† í° ì‚¬ìš©ëŸ‰", "API í˜¸ì¶œ ìˆ˜", "ë¹„ìš©", "ì‘ë‹µ ì‹œê°„"],
        index=0,
        key="llm_metric_view"
    )

with col4:
    if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", key="llm_refresh"):
        st.cache_data.clear()
        st.rerun()

st.markdown("---")

# LLM ì‚¬ìš©ëŸ‰ ë°ì´í„° ìƒì„±
@cached_function(ttl=60)
def get_llm_usage_data():
    """LLM ì‚¬ìš©ëŸ‰ ë°ì´í„° ìƒì„±"""
    
    models = [
        {
            'model_name': 'GPT-4',
            'provider': 'OpenAI',
            'input_tokens': 1_250_000,
            'output_tokens': 450_000,
            'total_calls': 1_245,
            'total_cost': 125.75,
            'avg_response_time': 3.2,
            'success_rate': 0.985,
            'usage_by_agent': {
                'Portfolio Manager': 35,
                'Market Analyst': 28,
                'Risk Controller': 15,
                'Technical Analyst': 22
            }
        },
        {
            'model_name': 'Claude-3',
            'provider': 'Anthropic',
            'input_tokens': 980_000,
            'output_tokens': 320_000,
            'total_calls': 856,
            'total_cost': 89.30,
            'avg_response_time': 2.8,
            'success_rate': 0.992,
            'usage_by_agent': {
                'Portfolio Manager': 40,
                'Market Analyst': 35,
                'Risk Controller': 12,
                'Technical Analyst': 13
            }
        },
        {
            'model_name': 'GPT-3.5-Turbo',
            'provider': 'OpenAI',
            'input_tokens': 2_100_000,
            'output_tokens': 650_000,
            'total_calls': 2_234,
            'total_cost': 45.80,
            'avg_response_time': 1.5,
            'success_rate': 0.978,
            'usage_by_agent': {
                'Portfolio Manager': 25,
                'Market Analyst': 30,
                'Risk Controller': 20,
                'Technical Analyst': 25
            }
        },
        {
            'model_name': 'Gemini-Pro',
            'provider': 'Google',
            'input_tokens': 750_000,
            'output_tokens': 280_000,
            'total_calls': 567,
            'total_cost': 32.40,
            'avg_response_time': 2.1,
            'success_rate': 0.975,
            'usage_by_agent': {
                'Portfolio Manager': 20,
                'Market Analyst': 45,
                'Risk Controller': 15,
                'Technical Analyst': 20
            }
        },
        {
            'model_name': 'Perplexity',
            'provider': 'Perplexity',
            'input_tokens': 450_000,
            'output_tokens': 180_000,
            'total_calls': 234,
            'total_cost': 28.90,
            'avg_response_time': 3.8,
            'success_rate': 0.988,
            'usage_by_agent': {
                'Portfolio Manager': 10,
                'Market Analyst': 60,
                'Risk Controller': 10,
                'Technical Analyst': 20
            }
        }
    ]
    
    # ì‹œê°„ë³„ ì‚¬ìš©ëŸ‰ ë°ì´í„° ìƒì„±
    dates = pd.date_range(start=datetime.now() - timedelta(days=30), end=datetime.now(), freq='D')
    
    for model in models:
        daily_data = []
        for date in dates:
            # ëœë¤í•˜ì§€ë§Œ ì¼ê´€ëœ íŒ¨í„´ ìƒì„±
            base_calls = model['total_calls'] / 30
            daily_calls = int(np.random.poisson(base_calls))
            daily_tokens = daily_calls * (model['input_tokens'] + model['output_tokens']) // model['total_calls']
            daily_cost = daily_calls * model['total_cost'] / model['total_calls']
            
            daily_data.append({
                'date': date,
                'calls': daily_calls,
                'input_tokens': int(daily_tokens * 0.7),
                'output_tokens': int(daily_tokens * 0.3),
                'cost': daily_cost,
                'avg_response_time': model['avg_response_time'] + np.random.normal(0, 0.5)
            })
        
        model['daily_usage'] = pd.DataFrame(daily_data)
    
    return models

# ì „ì²´ ì‚¬ìš©ëŸ‰ ìš”ì•½
st.subheader("ğŸ“Š LLM ì‚¬ìš©ëŸ‰ ìš”ì•½")
llm_data = get_llm_usage_data()

# í•„í„°ë§ëœ ë°ì´í„°
if model_filter:
    filtered_llm_data = [model for model in llm_data if model['model_name'] in model_filter]
else:
    filtered_llm_data = llm_data

# ì „ì²´ í†µê³„ ê³„ì‚°
total_input_tokens = sum(model['input_tokens'] for model in filtered_llm_data)
total_output_tokens = sum(model['output_tokens'] for model in filtered_llm_data)
total_calls = sum(model['total_calls'] for model in filtered_llm_data)
total_cost = sum(model['total_cost'] for model in filtered_llm_data)
avg_response_time = sum(model['avg_response_time'] * model['total_calls'] for model in filtered_llm_data) / total_calls if total_calls > 0 else 0

# ìš”ì•½ ì¹´ë“œ
col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    CountMetricCard(
        title="ğŸ”„ ì´ API í˜¸ì¶œ",
        value=total_calls,
        use_large_format=True,
        help_text="ì „ì²´ LLM API í˜¸ì¶œ íšŸìˆ˜"
    ).render()

with col2:
    CountMetricCard(
        title="ğŸ“ ì…ë ¥ í† í°",
        value=total_input_tokens,
        use_large_format=True,
        help_text="ì´ ì…ë ¥ í† í° ìˆ˜"
    ).render()

with col3:
    CountMetricCard(
        title="ğŸ’¬ ì¶œë ¥ í† í°",
        value=total_output_tokens,
        use_large_format=True,
        help_text="ì´ ì¶œë ¥ í† í° ìˆ˜"
    ).render()

with col4:
    FinancialMetricCard(
        title="ğŸ’° ì´ ë¹„ìš©",
        value=total_cost,
        help_text="LLM API ì‚¬ìš© ì´ ë¹„ìš©"
    ).render()

with col5:
    st.metric(
        "âš¡ í‰ê·  ì‘ë‹µì‹œê°„",
        f"{avg_response_time:.1f}ì´ˆ",
        help="API í˜¸ì¶œ í‰ê·  ì‘ë‹µ ì‹œê°„"
    )

st.markdown("---")

# ëª¨ë¸ë³„ ë¹„êµ
st.subheader("ğŸ¤– ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ ë¹„êµ")

if filtered_llm_data:
    # ëª¨ë¸ ë¹„êµ í…Œì´ë¸”
    comparison_data = []
    for model in filtered_llm_data:
        efficiency = (model['input_tokens'] + model['output_tokens']) / model['total_cost'] if model['total_cost'] > 0 else 0
        
        comparison_data.append({
            'ëª¨ë¸': model['model_name'],
            'ì œê³µì‚¬': model['provider'],
            'API í˜¸ì¶œ': f"{model['total_calls']:,}",
            'ì´ í† í°': format_large_number(model['input_tokens'] + model['output_tokens']),
            'ë¹„ìš©': format_currency(model['total_cost']),
            'ì‘ë‹µì‹œê°„': f"{model['avg_response_time']:.1f}ì´ˆ",
            'ì„±ê³µë¥ ': format_percentage(model['success_rate']),
            'í† í°/ë‹¬ëŸ¬': f"{efficiency:,.0f}"
        })
    
    st.dataframe(pd.DataFrame(comparison_data), use_container_width=True, hide_index=True)
    
    # ëª¨ë¸ë³„ ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“Š ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ ë¶„í¬")
        
        chart_data = pd.DataFrame([
            {
                'model': model['model_name'],
                'calls': model['total_calls'],
                'tokens': model['input_tokens'] + model['output_tokens'],
                'cost': model['total_cost']
            }
            for model in filtered_llm_data
        ])
        
        if metric_view == "í† í° ì‚¬ìš©ëŸ‰":
            fig = px.bar(chart_data, x='model', y='tokens', title="", color='model')
            fig.update_yaxes(title="í† í° ìˆ˜")
        elif metric_view == "API í˜¸ì¶œ ìˆ˜":
            fig = px.bar(chart_data, x='model', y='calls', title="", color='model')
            fig.update_yaxes(title="í˜¸ì¶œ ìˆ˜")
        elif metric_view == "ë¹„ìš©":
            fig = px.bar(chart_data, x='model', y='cost', title="", color='model')
            fig.update_yaxes(title="ë¹„ìš© ($)")
        else:  # ì‘ë‹µ ì‹œê°„
            response_data = pd.DataFrame([
                {'model': model['model_name'], 'response_time': model['avg_response_time']}
                for model in filtered_llm_data
            ])
            fig = px.bar(response_data, x='model', y='response_time', title="", color='model')
            fig.update_yaxes(title="ì‘ë‹µ ì‹œê°„ (ì´ˆ)")
        
        fig.update_xaxes(title="ëª¨ë¸")
        fig.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ¥§ ë¹„ìš© ë¶„í¬")
        
        cost_data = pd.DataFrame([
            {'model': model['model_name'], 'cost': model['total_cost']}
            for model in filtered_llm_data
        ])
        
        fig = px.pie(cost_data, values='cost', names='model', title="")
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# ì‹œê³„ì—´ ë¶„ì„
st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ì‚¬ìš©ëŸ‰ ë¶„ì„")

if filtered_llm_data:
    start_date, end_date = get_time_range_filter(time_range)
    
    # ì‹œê³„ì—´ ì°¨íŠ¸
    fig = go.Figure()
    
    for model in filtered_llm_data:
        daily_data = model['daily_usage']
        filtered_data = daily_data[
            (daily_data['date'] >= start_date) & (daily_data['date'] <= end_date)
        ]
        
        if not filtered_data.empty:
            if metric_view == "í† í° ì‚¬ìš©ëŸ‰":
                y_data = filtered_data['input_tokens'] + filtered_data['output_tokens']
                y_title = "í† í° ìˆ˜"
            elif metric_view == "API í˜¸ì¶œ ìˆ˜":
                y_data = filtered_data['calls']
                y_title = "í˜¸ì¶œ ìˆ˜"
            elif metric_view == "ë¹„ìš©":
                y_data = filtered_data['cost']
                y_title = "ë¹„ìš© ($)"
            else:  # ì‘ë‹µ ì‹œê°„
                y_data = filtered_data['avg_response_time']
                y_title = "ì‘ë‹µ ì‹œê°„ (ì´ˆ)"
            
            fig.add_trace(go.Scatter(
                x=filtered_data['date'],
                y=y_data,
                mode='lines+markers',
                name=model['model_name'],
                line=dict(width=3),
                marker=dict(size=4)
            ))
    
    fig.update_layout(
        title=f"ëª¨ë¸ë³„ {metric_view} ì¶”ì´",
        xaxis_title="ë‚ ì§œ",
        yaxis_title=y_title,
        height=450,
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# ì—ì´ì „íŠ¸ë³„ LLM ì‚¬ìš©ëŸ‰
st.subheader("ğŸ¤– ì—ì´ì „íŠ¸ë³„ LLM ì‚¬ìš© ë¶„ì„")

if filtered_llm_data:
    # ì—ì´ì „íŠ¸ë³„ ì‚¬ìš©ëŸ‰ ì§‘ê³„
    agent_usage = {}
    agents = ['Portfolio Manager', 'Market Analyst', 'Risk Controller', 'Technical Analyst']
    
    for agent in agents:
        agent_usage[agent] = {
            'total_usage': 0,
            'models': {},
            'total_cost': 0
        }
    
    for model in filtered_llm_data:
        for agent, percentage in model['usage_by_agent'].items():
            if agent in agent_usage:
                usage_calls = int(model['total_calls'] * percentage / 100)
                usage_cost = model['total_cost'] * percentage / 100
                
                agent_usage[agent]['total_usage'] += usage_calls
                agent_usage[agent]['models'][model['model_name']] = usage_calls
                agent_usage[agent]['total_cost'] += usage_cost
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“Š ì—ì´ì „íŠ¸ë³„ ì‚¬ìš©ëŸ‰")
        
        agent_data = []
        for agent, data in agent_usage.items():
            agent_data.append({
                'agent': agent,
                'usage': data['total_usage'],
                'cost': data['total_cost']
            })
        
        agent_df = pd.DataFrame(agent_data)
        fig = px.bar(agent_df, x='agent', y='usage', title="", color='agent')
        fig.update_layout(height=400, showlegend=False)
        fig.update_xaxes(title="ì—ì´ì „íŠ¸")
        fig.update_yaxes(title="API í˜¸ì¶œ ìˆ˜")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ’° ì—ì´ì „íŠ¸ë³„ ë¹„ìš©")
        
        fig = px.bar(agent_df, x='agent', y='cost', title="", color='agent')
        fig.update_layout(height=400, showlegend=False)
        fig.update_xaxes(title="ì—ì´ì „íŠ¸")
        fig.update_yaxes(title="ë¹„ìš© ($)")
        st.plotly_chart(fig, use_container_width=True)
    
    # ì—ì´ì „íŠ¸-ëª¨ë¸ ë§¤íŠ¸ë¦­ìŠ¤
    st.markdown("### ğŸ” ì—ì´ì „íŠ¸-ëª¨ë¸ ì‚¬ìš© ë§¤íŠ¸ë¦­ìŠ¤")
    
    matrix_data = []
    for agent, data in agent_usage.items():
        row = {'Agent': agent}
        for model in filtered_llm_data:
            model_name = model['model_name']
            row[model_name] = data['models'].get(model_name, 0)
        matrix_data.append(row)
    
    matrix_df = pd.DataFrame(matrix_data)
    st.dataframe(matrix_df, use_container_width=True, hide_index=True)

st.markdown("---")

# ì„±ëŠ¥ ë° íš¨ìœ¨ì„± ë¶„ì„
st.subheader("âš¡ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± ë¶„ì„")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("#### ğŸ¯ ì‘ë‹µ ì‹œê°„ ë¶„í¬")
    
    response_times = [model['avg_response_time'] for model in filtered_llm_data]
    model_names = [model['model_name'] for model in filtered_llm_data]
    
    fig = px.box(y=response_times, title="")
    fig.update_layout(height=300)
    fig.update_yaxes(title="ì‘ë‹µ ì‹œê°„ (ì´ˆ)")
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("#### ğŸ“ˆ ì„±ê³µë¥  ë¹„êµ")
    
    success_rates = [model['success_rate'] * 100 for model in filtered_llm_data]
    
    fig = px.bar(x=model_names, y=success_rates, title="")
    fig.update_layout(height=300, showlegend=False)
    fig.update_xaxes(title="ëª¨ë¸")
    fig.update_yaxes(title="ì„±ê³µë¥  (%)")
    fig.add_hline(y=95, line_dash="dash", line_color="red", annotation_text="ìµœì†Œ ê¸°ì¤€ì„ ")
    st.plotly_chart(fig, use_container_width=True)

with col3:
    st.markdown("#### ğŸ’ ë¹„ìš© íš¨ìœ¨ì„±")
    
    # í† í°ë‹¹ ë¹„ìš© ê³„ì‚°
    efficiency_data = []
    for model in filtered_llm_data:
        total_tokens = model['input_tokens'] + model['output_tokens']
        cost_per_token = model['total_cost'] / total_tokens if total_tokens > 0 else 0
        efficiency_data.append({
            'model': model['model_name'],
            'cost_per_1k_tokens': cost_per_token * 1000
        })
    
    eff_df = pd.DataFrame(efficiency_data)
    fig = px.bar(eff_df, x='model', y='cost_per_1k_tokens', title="")
    fig.update_layout(height=300, showlegend=False)
    fig.update_xaxes(title="ëª¨ë¸")
    fig.update_yaxes(title="1K í† í°ë‹¹ ë¹„ìš© ($)")
    st.plotly_chart(fig, use_container_width=True)

# ì‹¤ì‹œê°„ ì•Œë¦¼ ë° ì„ê³„ê°’
st.markdown("---")
st.subheader("ğŸš¨ ì•Œë¦¼ ë° ì„ê³„ê°’ ì„¤ì •")

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### âš™ï¸ ì„ê³„ê°’ ì„¤ì •")
    
    daily_cost_limit = st.number_input("ì¼ì¼ ë¹„ìš© í•œë„ ($)", min_value=0.0, value=50.0, step=1.0)
    monthly_token_limit = st.number_input("ì›”ê°„ í† í° í•œë„ (M)", min_value=0.0, value=10.0, step=0.5)
    response_time_threshold = st.number_input("ì‘ë‹µ ì‹œê°„ ì„ê³„ê°’ (ì´ˆ)", min_value=0.0, value=5.0, step=0.1)
    
    if st.button("ğŸ’¾ ì„ê³„ê°’ ì €ì¥"):
        st.success("ì„ê³„ê°’ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

with col2:
    st.markdown("#### ğŸ”” í˜„ì¬ ìƒíƒœ")
    
    # í˜„ì¬ ì¼ì¼ ë¹„ìš© (ë”ë¯¸)
    current_daily_cost = sum(model['total_cost'] for model in filtered_llm_data) / 30
    
    if current_daily_cost > daily_cost_limit:
        st.error(f"âš ï¸ ì¼ì¼ ë¹„ìš© ì´ˆê³¼: ${current_daily_cost:.2f} / ${daily_cost_limit:.2f}")
    else:
        st.success(f"âœ… ì¼ì¼ ë¹„ìš© ì •ìƒ: ${current_daily_cost:.2f} / ${daily_cost_limit:.2f}")
    
    # ì‘ë‹µ ì‹œê°„ ìƒíƒœ
    max_response_time = max(model['avg_response_time'] for model in filtered_llm_data)
    
    if max_response_time > response_time_threshold:
        st.warning(f"âš ï¸ ì‘ë‹µ ì‹œê°„ ëŠë¦¼: {max_response_time:.1f}ì´ˆ > {response_time_threshold:.1f}ì´ˆ")
    else:
        st.success(f"âœ… ì‘ë‹µ ì‹œê°„ ì–‘í˜¸: {max_response_time:.1f}ì´ˆ")

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ§  LLM ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ | ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {timestamp} | ì‹¤ì‹œê°„ ì¶”ì 
    </div>
    """.format(timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
    unsafe_allow_html=True
)